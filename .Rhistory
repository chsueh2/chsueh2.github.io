# train model
fit <- train(
form = formula,
data = df_train,
method = method,
preProcess = c("center", "scale"),
trControl = trControl,
tuneGrid = tuneGrid, ...)
# timer - report time used
timer <- proc.time() - proc_timer
print(timer)
# print the best tune if there is a tuning parameter
if(is.null(tuneGrid)){
print("No tuning parameter")
} else {
# print the best tune
print("The best tune is found with:")
print(glue("\t{names(fit$bestTune)} = {fit$bestTune[1,]}"))
if(plot) plot_modelinfo(fit)
}
# make prediction on test set
pred <- predict(fit, newdata = df_test)
# return performance metric or confusion matrix depending on response type
if(is.numeric(pred)){
# numeric response
performance <- postResample(pred, obs = df_test[, 1])
# print performance metrics
print("Performance metrics:")
print(performance)
# return the performance metric
return(list(method = method, performance = performance, timer = timer))
} else if(is.factor(pred)){
# categorical response
cfm <- confusionMatrix(df_test[, 1], pred)
# print confusion matrix and accuracy
print("Confusion table:")
print(cfm$table)
print(glue("Accuracy = {cfm$overall['Accuracy']}"))
# return the confusion matrix
return(list(method = method, performance = cfm, timer = timer))
}
}
# a helper function to plot the metric vs. the tuning parameter
plot_modelinfo <- function(fit, plot_wrt = 1){
# get model info
model <- fit$modelInfo$label
parameter <- fit$modelInfo$parameters$parameter
description <- fit$modelInfo$parameters$label
# plot parameter vs metrics
p <- fit$results %>%
select(-setdiff(parameter, names(fit$results)[plot_wrt])) %>%
rename_at(1, ~"x") %>%
pivot_longer(cols = -1, names_to = "Metric") %>%
ggplot(aes(x, value, color = Metric)) +
geom_point() +
geom_line() +
facet_grid(rows = vars(Metric), scales = "free_y") +
labs(
title = glue("{model}: Hyperparameter Tuning"),
x = glue("{parameter} ({description})")
)
print(p)
return(p)
}
# initiate a list to save the results
results <- list()
# configure the model to use
method <-  "knn"
tuneGrid <- expand.grid(k = 1:15)
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <- append(results, list(fit))
# configure the model to use
method <-  "kknn"
tuneGrid <- expand.grid(kmax = 1:15, distance = 2, kernel = "rectangular")
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <- append(results, list(fit))
View(results)
# configure the model to use
method <-  "rf"
tuneGrid <- expand.grid(mtry = 1:15)
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <- append(results, list(fit))
expand.grid(mtry = 1:15, splitrule = "variance", min.node.size = NULL)
z <- expand.grid(mtry = 1:15, splitrule = "variance", min.node.size = NULL)
z <- expand.grid(mtry = 1:15, splitrule = "variance", min.node.size = 1)
z
z <- expand.grid(mtry = 1:15, splitrule = "variance", min.node.size = NULL)
z
knitr::opts_chunk$set(fig.path = "../images/")
# packages
if (!require("pacman")) utils::install.packages("pacman", dependencies = TRUE)
pacman::p_load(
here,
stats, rlang,
tidyverse,
glue, scales,
caret, class, kknn, randomForest, ranger
)
# helper function: string concatenation (ex: "act" %&% "5")
'%&%' <- function(x, y) paste0(x, y)
# configure the model to use
method <-  "ranger"
tuneGrid <- expand.grid(mtry = 1:15, splitrule = "variance", min.node.size = 1)
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# configure the model to use
method <-  "ranger"
tuneGrid <- expand.grid(mtry = 1:15, splitrule = "variance", min.node.size = 1)
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
aaa <- results
data("GermanCredit")
df <- GermanCredit %>%
mutate(Class = factor(Class)) %>%
relocate(Class) %>%
# remove these variables since it only contains one level
select(-Personal.Female.Single, -Purpose.Vacation)
# split train/test sets
set.seed(90)
trainIndex <- createDataPartition(df$Class, p = 0.7, list = FALSE)
df_train <- df[trainIndex, ]
df_test <- df[-trainIndex, ]
# initiate a list to save the results
results <- list()
# configure the model to use
method <-  "knn"
tuneGrid <- expand.grid(k = 1:15)
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <- append(results, list(fit))
# configure the model to use
method <-  "kknn"
tuneGrid <- expand.grid(kmax = 1:15, distance = 2, kernel = "rectangular")
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <- append(results, list(fit))
# configure the model to use
method <-  "rf"
tuneGrid <- expand.grid(mtry = 1:15)
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <- append(results, list(fit))
# configure the model to use
method <-  "ranger"
tuneGrid <- expand.grid(mtry = 1:15, splitrule = "gini", min.node.size = 1)
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <- append(results, list(fit))
z <- results[[1]]
z$method
z$timer
typeof(z$timer)
str(z$timer)
z$performance$table
z$performance$overall
zz <- tibble(z$method, z$performance$overall, z$timer)
zz <- tibble(c(z$method, z$performance$overall, z$timer))
zz
zz <- tibble(z$method)
zz
zz <- tibble(z$performance$overall)
zz
zz <- as.tibble(z$performance$overall)
zz <- as_tibble(z$performance$overall)
zz
zz <- as.tibble(z$performance$overall)
zz
z$performance$overall
z$performance$overall["Accuracy"]
str(z$timer)
z$timer
df_comparison <- tibble()
for (i in length(results)) {
item <- results[[i]]
df_comparison <- df_comparison %>%
bind_rows(
tibble(
method =item$method,
accuracy = item$performance$overall["Accuracy"],
kappa = item$performance$overall["Kappa"],
time_elapsed = item$timer["elapsed"]
)
)
}
df_comparison
df_comparison <- tibble()
for (i in length(results)) {
item <- results[[i]]
dfz <- tibble(
method =item$method,
accuracy = item$performance$overall["Accuracy"],
kappa = item$performance$overall["Kappa"],
time_elapsed = item$timer["elapsed"]
)
df_comparison <- bind_rows(df_comparison, dfz)
}
df_comparison
df_comparison <- tibble()
for (i in seq_along(results)) {
item <- results[[i]]
dfz <- tibble(
method =item$method,
accuracy = item$performance$overall["Accuracy"],
kappa = item$performance$overall["Kappa"],
time_elapsed = item$timer["elapsed"]
)
df_comparison <- bind_rows(df_comparison, dfz)
}
df_comparison
df_comparison <- tibble()
for (i in seq_along(results)) {
item <- results[[i]]
df_comparison <- tibble(
method =item$method,
accuracy = item$performance$overall["Accuracy"],
kappa = item$performance$overall["Kappa"],
time_elapsed = item$timer["elapsed"]
) %>%
bind_rows(df_comparison)
#df_comparison <- bind_rows(df_comparison, dfz)
}
df_comparison
df_comparison <- tibble()
for (i in seq_along(results)) {
item <- results[[i]]
df_comparison <-
tibble(
method =item$method,
accuracy = item$performance$overall["Accuracy"],
kappa = item$performance$overall["Kappa"],
time_elapsed = item$timer["elapsed"]
) %>%
bind_rows(df_comparison, .)
#df_comparison <- bind_rows(df_comparison, dfz)
}
df_comparison
# configure the model to use
method <-  "kknn_Manhattan"
tuneGrid <- expand.grid(kmax = 1:15, distance = 1, kernel = "rectangular")
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
source("~/.active-rstudio-document", echo=TRUE)
method <- "knn"
p <- list(a = 1, b = 2)
p
p <- list(!!sym(method) = 1, b = 2)
p <- list(sym(method) = 1, b = 2)
p <- list(sym(method) := 1, b = 2)
p <- list(enquo(method) = 1, b = 2)
p <- list(!!enquo(method) = 1, b = 2)
p <- list(!!quo(method) = 1, b = 2)
p <- list(!!method = 1, b = 2)
p <- tibble(!!method = 1, b = 2)
p
p <- tibble(!!method = 1, b = 2)
p <- tibble(method = 1, b = 2)
p
p <- tibble(!!method = 1, b = 2)
p <- tibble((!!method) = 1, b = 2)
p <- tibble(!!sym(method) = 1, b = 2)
p <- tibble({{method}} = 1, b = 2)
p <- tibble({{method}} := 1, b = 2)
p
p <- list({{method}} := 1, b = 2)
p
p <- tibble({{method}} := 1, b = 2)
p
# initiate a list to save the results
results <- tibble()
# configure the model to use
name <- "knn_Euclidean"
method <-  "knn"
tuneGrid <- expand.grid(k = 1:15)
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <-
tibble(
name = name,
method = method,
accuracy = fit$performance$overall["Accuracy"],
kappa = fit$performance$overall["Kappa"],
time_elapsed = fit$timer["elapsed"]
) %>%
bind_rows(results)
View(results)
# configure the model to use
name <- "knn_Manhattan"
method <-  "kknn"
tuneGrid <- expand.grid(kmax = 1:15, distance = 1, kernel = "rectangular")
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <-
tibble(
name = name,
method = method,
accuracy = fit$performance$overall["Accuracy"],
kappa = fit$performance$overall["Kappa"],
time_elapsed = fit$timer["elapsed"]
) %>%
bind_rows(results)
View(results)
# configure the model to use
name <- "knn_Minkowski"
method <-  "kknn"
tuneGrid <- expand.grid(kmax = 1:15, distance = 2, kernel = "rectangular")
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <-
tibble(
name = name,
method = method,
accuracy = fit$performance$overall["Accuracy"],
kappa = fit$performance$overall["Kappa"],
time_elapsed = fit$timer["elapsed"]
) %>%
bind_rows(results)
View(results)
# initiate a list to save the results
results <- tibble()
# configure the model to use
name <- "KNN Euclidean"
method <-  "knn"
tuneGrid <- expand.grid(k = 1:15)
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <-
tibble(
name = name,
method = method,
accuracy = fit$performance$overall["Accuracy"],
kappa = fit$performance$overall["Kappa"],
time_elapsed = fit$timer["elapsed"]
) %>%
bind_rows(results)
# configure the model to use
name <- "KNN Euclidean"
method <-  "kknn"
tuneGrid <- expand.grid(kmax = 1:15, distance = 2, kernel = "rectangular")
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <-
tibble(
name = name,
method = method,
accuracy = fit$performance$overall["Accuracy"],
kappa = fit$performance$overall["Kappa"],
time_elapsed = fit$timer["elapsed"]
) %>%
bind_rows(results)
View(results)
# configure the model to use
name <- "KNN Manhattan"
method <-  "kknn"
tuneGrid <- expand.grid(kmax = 1:15, distance = 1, kernel = "rectangular")
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <-
tibble(
name = name,
method = method,
accuracy = fit$performance$overall["Accuracy"],
kappa = fit$performance$overall["Kappa"],
time_elapsed = fit$timer["elapsed"]
) %>%
bind_rows(results)
# configure the model to use
name <- "Random Forests"
method <-  "rf"
tuneGrid <- expand.grid(mtry = 1:15)
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <-
tibble(
name = name,
method = method,
accuracy = fit$performance$overall["Accuracy"],
kappa = fit$performance$overall["Kappa"],
time_elapsed = fit$timer["elapsed"]
) %>%
bind_rows(results)
# configure the model to use
name <- "Random Forests"
method <-  "ranger"
tuneGrid <- expand.grid(mtry = 1:15, splitrule = "gini", min.node.size = 1)
# fit the model
fit <- fit_model(
Class ~ ., df_train, df_test, method = method,
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 3),
tuneGrid = tuneGrid
)
# save the result
results <-
tibble(
name = name,
method = method,
accuracy = fit$performance$overall["Accuracy"],
kappa = fit$performance$overall["Kappa"],
time_elapsed = fit$timer["elapsed"]
) %>%
bind_rows(results)
# sort the results
results %>%
arrange(desc(accuracy), time_elapsed)
library(here)
library(rmarkdown)
library(knitr)
# input rmarkdown file
# -----------------------------------------------
input <- here("_Rmd", "2022-07-16-ML.Rmd")
rmarkdown::render(
input = input,
output_format = github_document(html_preview = FALSE),
#output_file = "README.md"
output_dir = here("_posts")
)
library(here)
library(rmarkdown)
library(knitr)
# input rmarkdown file
# -----------------------------------------------
input <- here("_Rmd", "2022-07-22-next-step.Rmd")
rmarkdown::render(
input = input,
output_format = github_document(html_preview = FALSE),
#output_file = "README.md"
output_dir = here("_posts")
)
